{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3eeb53c",
   "metadata": {},
   "source": [
    "# Intro to Data Pipelines — Hands-On Lab for ML@P Accelerator Lab 2\n",
    "\n",
    "## Overview\n",
    "This lab is designed to give you practical experience with NumPy, Pandas, and Exploratory Data Analysis (EDA). \n",
    "\n",
    "The focus of this lab is not on writing perfect code, but on developing the ability to reason about data: its structure, quality, distributions, and relationships.\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "- Create and manipulate NumPy arrays\n",
    "- Use vectorized operations instead of loops\n",
    "- Apply boolean masking and aggregation functions\n",
    "- Load and inspect tabular data using Pandas\n",
    "- Identify numerical and categorical columns\n",
    "- Handle missing values appropriately\n",
    "- Perform univariate and multivariate exploratory analysis\n",
    "- Interpret plots and summarize insights in words\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Lab Structure\n",
    "This lab is divided into two main parts:\n",
    "\n",
    "1. NumPy Exercises  \n",
    "\n",
    "\n",
    "2. Exploratory Data Analysis (EDA) with Pandas  \n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3f5da64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918197be",
   "metadata": {},
   "source": [
    "## Part 1: NumPy Exercises\n",
    "**Tasks:**\n",
    "1. Create a 1D NumPy array containing the integers from 1 to 10 (inclusive)\n",
    "2. Create a 2D NumPy array of size (3, 3)\n",
    "3. For both arrays, print: ndim, shape, size and dtype\n",
    "\n",
    "4. Given\n",
    "arr = np.array([\n",
    "    [5, 10, 15],\n",
    "    [20, 25, 30],\n",
    "    [35, 40, 45]\n",
    "])\n",
    "\n",
    "    Extract the first row.\n",
    "    Extract the last column.\n",
    "    Extract the element with value 25.\n",
    "\n",
    "5. Using the array in part 1, filter for elements greater than 5\n",
    "6. Using the array in part 1, set all elements below 4 to 0\n",
    "7. Given data = np.array([10, 20, np.nan, 40, np.nan, 60])\n",
    "\n",
    "    Replace all NaNs with mean of non-nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c7dcc720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q3:\n",
      "1\n",
      "(10,)\n",
      "10\n",
      "int64\n",
      "\n",
      "2\n",
      "(3, 3)\n",
      "9\n",
      "int64\n",
      "\n",
      "Q4:\n",
      "[ 5 10 15]\n",
      "[ 5 20 35]\n",
      "25\n",
      "\n",
      "Q5:\n",
      "[ 6  7  8  9 10]\n",
      "\n",
      "Q6:\n",
      "[ 0  0  0  4  5  6  7  8  9 10]\n",
      "\n",
      "Q7:\n",
      "[10.  20.  32.5 40.  32.5 60. ]\n"
     ]
    }
   ],
   "source": [
    "# Do your work here!\n",
    "\n",
    "# 1\n",
    "arr1 = np.array([1,2,3,4,5,6,7,8,9,10])\n",
    "# print(\"1:\", arr1)\n",
    "\n",
    "# 2\n",
    "arr2 = np.array([[1,2,3], [4,5,6], [7,8,9]])\n",
    "# print(\"2:\", arr2)\n",
    "\n",
    "# 3\n",
    "print(\"\\nQ3:\")\n",
    "\n",
    "print(arr1.ndim)\n",
    "print(arr1.shape)\n",
    "print(arr1.size)\n",
    "print(arr1.dtype)\n",
    "\n",
    "print()\n",
    "\n",
    "print(arr2.ndim)\n",
    "print(arr2.shape)\n",
    "print(arr2.size)\n",
    "print(arr2.dtype)\n",
    "\n",
    "# 4\n",
    "print(\"\\nQ4:\")\n",
    "\n",
    "arr3 = np.array([\n",
    "    [5, 10, 15],\n",
    "    [20, 25, 30],\n",
    "    [35, 40, 45]\n",
    "])\n",
    "\n",
    "print(arr3[0])\n",
    "print(arr3[:,0])\n",
    "print(arr3[1,1])\n",
    "\n",
    "# 5\n",
    "print(\"\\nQ5:\")\n",
    "\n",
    "print(arr1[arr1 > 5])\n",
    "\n",
    "# 6\n",
    "print(\"\\nQ6:\")\n",
    "\n",
    "arr4 = arr1.copy()\n",
    "arr4[arr4 < 4] = 0\n",
    "print(arr4)\n",
    "\n",
    "# 7\n",
    "print(\"\\nQ7:\")\n",
    "\n",
    "data = np.array([10, 20, np.nan, 40, np.nan, 60])\n",
    "data = np.where(np.isnan(data), np.nanmean(data), data)\n",
    "print(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b86530",
   "metadata": {},
   "source": [
    "## Part 2: EDA\n",
    "\n",
    "For this part, we want you to explore a dataset of your choice by yourself! Head on over to Kaggle (https://www.kaggle.com/) to find a plethora of datasets in a plethora of fields. Try to find a dataset that will test skills taught in the workshop.\n",
    "\n",
    "Can't find something? Use the train Titanic dataset: https://www.kaggle.com/competitions/titanic/data?select=train.csv\n",
    "\n",
    "### Step 1 - Load the dataset using Pandas.\n",
    "\n",
    "**Tasks:**\n",
    "1. Read the CSV file into a DataFrame.\n",
    "2. Display the first 5 rows of the dataset.\n",
    "3. Print the shape of the DataFrame.\n",
    "4. Use info() to inspect column data types and missing values.\n",
    "5. Use describe() to view summary statistics for numerical columns.\n",
    "\n",
    "**Questions to answer:**\n",
    "- How many rows and columns does the dataset have?\n",
    "- Which columns are numerical?\n",
    "- Which columns are categorical?\n",
    "- Are there any obvious issues with data types or missing values?\n",
    "\n",
    "---\n",
    "\n",
    "### Step 2 — Identify and Handle Missing Values\n",
    "\n",
    "**Tasks:**\n",
    "1. Identify how many missing values exist in each column.\n",
    "2. Decide which numerical columns should be imputed using:\n",
    "   - Mean, or\n",
    "   - Median, or\n",
    "   - Mode\n",
    "3. Perform the imputation.\n",
    "4. Verify that missing values have been handled correctly.\n",
    "\n",
    "**Questions to answer:**\n",
    "- Which columns contained missing values?\n",
    "- Why did you choose mean or median for each column?\n",
    "- Were any columns dropped? If yes, explain why.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 3 — Univariate Analysis (Numerical Columns)\n",
    "\n",
    "Analyze numerical columns one at a time.\n",
    "\n",
    "**Tasks:**\n",
    "For at least two numerical columns:\n",
    "1. Plot a histogram.\n",
    "2. Plot a boxplot.\n",
    "3. Examine the summary statistics.\n",
    "\n",
    "**Questions to answer:**\n",
    "- Is the distribution skewed?\n",
    "- Are there extreme values or outliers?\n",
    "- Would scaling be required for this column before modeling?\n",
    "\n",
    "---\n",
    "\n",
    "### Step 4 — Univariate Analysis (Categorical Columns)\n",
    "\n",
    "Analyze categorical columns individually.\n",
    "\n",
    "**Tasks:**\n",
    "1. Use value_counts() for each categorical column.\n",
    "2. Create a bar chart showing the distribution of categories.\n",
    "\n",
    "**Questions to answer:**\n",
    "- Which category appears most frequently?\n",
    "- Is there any noticeable class imbalance?\n",
    "\n",
    "---\n",
    "\n",
    "### Step 5 — Feature Engineering \n",
    "\n",
    "Create at least one new feature that could be useful for analysis.\n",
    "\n",
    "**Questions to answer:**\n",
    "- Why might this feature be useful?\n",
    "- Is this new feature numerical or categorical?\n",
    "\n",
    "---\n",
    "\n",
    "### Step 6 — Multivariate Analysis\n",
    "\n",
    "Explore relationships between variables.\n",
    "\n",
    "#### Numerical vs Numerical\n",
    "**Tasks:**\n",
    "1. Create a scatter plot between 2 pairs of numerical variables\n",
    "2. Compute the correlation between these variables.\n",
    "\n",
    "**Questions to answer:**\n",
    "- Is there a visible relationship?\n",
    "- Is the correlation positive, negative or close to 0\n",
    "\n",
    "\n",
    "#### Categorical vs Numerical\n",
    "**Tasks:**\n",
    "1. Find statistics of numerical features after being grouped by the categorical features\n",
    "\n",
    "**Questions to answer:**\n",
    "- Are there any significant differences in the statistics across groups in the categorical variable?\n",
    "\n",
    "---\n",
    "\n",
    "### Step 7 — Outlier Analysis\n",
    "\n",
    "Focus on one numerical column with potential outliers.\n",
    "\n",
    "**Tasks:**\n",
    "1. Identify potential outliers using visual inspection (boxplot).\n",
    "2. Try to decide whether these outliers are:\n",
    "   - Data errors, or\n",
    "   - Legitimate extreme values\n",
    "\n",
    "**Questions to answer:**\n",
    "- Should these outliers be removed?\n",
    "- What is the IQR range, and upper, lower limits for removal?\n",
    "\n",
    "---\n",
    "\n",
    "### Step 8 — Final Insights\n",
    "\n",
    "Summarize your findings.\n",
    "\n",
    "**Tasks:**\n",
    "1. Write at least three meaningful insights derived from your analysis.\n",
    "2. Reference plots or statistics where appropriate.\n",
    "\n",
    "Examples of insights:\n",
    "- Patterns between variables\n",
    "- Differences across categories\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9e366884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Transaction ID    Item Quantity Price Per Unit Total Spent  Payment Method  \\\n",
      "0    TXN_1961373  Coffee        2            2.0         4.0     Credit Card   \n",
      "1    TXN_4977031    Cake        4            3.0        12.0            Cash   \n",
      "2    TXN_4271903  Cookie        4            1.0       ERROR     Credit Card   \n",
      "3    TXN_7034554   Salad        2            5.0        10.0         UNKNOWN   \n",
      "4    TXN_3160411  Coffee        2            2.0         4.0  Digital Wallet   \n",
      "\n",
      "   Location Transaction Date  \n",
      "0  Takeaway       2023-09-08  \n",
      "1  In-store       2023-05-16  \n",
      "2  In-store       2023-07-19  \n",
      "3   UNKNOWN       2023-04-27  \n",
      "4  In-store       2023-06-11  \n",
      "(10000, 8)\n",
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype\n",
      "---  ------            --------------  -----\n",
      " 0   Transaction ID    10000 non-null  str  \n",
      " 1   Item              9667 non-null   str  \n",
      " 2   Quantity          9862 non-null   str  \n",
      " 3   Price Per Unit    9821 non-null   str  \n",
      " 4   Total Spent       9827 non-null   str  \n",
      " 5   Payment Method    7421 non-null   str  \n",
      " 6   Location          6735 non-null   str  \n",
      " 7   Transaction Date  9841 non-null   str  \n",
      "dtypes: str(8)\n",
      "memory usage: 625.1 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction ID</th>\n",
       "      <th>Item</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Price Per Unit</th>\n",
       "      <th>Total Spent</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Location</th>\n",
       "      <th>Transaction Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000</td>\n",
       "      <td>9667</td>\n",
       "      <td>9862</td>\n",
       "      <td>9821</td>\n",
       "      <td>9827</td>\n",
       "      <td>7421</td>\n",
       "      <td>6735</td>\n",
       "      <td>9841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>10000</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>TXN_1961373</td>\n",
       "      <td>Juice</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>UNKNOWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1171</td>\n",
       "      <td>2013</td>\n",
       "      <td>2429</td>\n",
       "      <td>979</td>\n",
       "      <td>2291</td>\n",
       "      <td>3022</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Transaction ID   Item Quantity Price Per Unit Total Spent  \\\n",
       "count           10000   9667     9862           9821        9827   \n",
       "unique          10000     10        7              8          19   \n",
       "top       TXN_1961373  Juice        5            3.0         6.0   \n",
       "freq                1   1171     2013           2429         979   \n",
       "\n",
       "        Payment Method  Location Transaction Date  \n",
       "count             7421      6735             9841  \n",
       "unique               5         4              367  \n",
       "top     Digital Wallet  Takeaway          UNKNOWN  \n",
       "freq              2291      3022              159  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do your work here!\n",
    "\n",
    "### ! Step 1 - Load the dataset using Pandas.\n",
    "\n",
    "# **Tasks:**\n",
    "# TODO 1. Read the CSV file into a DataFrame.\n",
    "# TODO 2. Display the first 5 rows of the dataset.\n",
    "# TODO 3. Print the shape of the DataFrame.\n",
    "# TODO 4. Use info() to inspect column data types and missing values.\n",
    "# TODO 5. Use describe() to view summary statistics for numerical columns.\n",
    "\n",
    "# **Questions to answer:**\n",
    "# ?- How many rows and columns does the dataset have?\n",
    "    # ^ rows = 10,000\n",
    "    # ^ cols = 8\n",
    "\n",
    "# ?- Which columns are numerical?\n",
    "# ?- Which columns are categorical?\n",
    "    # ^ Types of data for the columns, Transaction ID: Numerical, Item: Categorical, Quantity: Numerical, Price Per Unit: Numerical\n",
    "    # ^ Total Spent: Numerical, Payment Method: Categorical, Location: Categorical, Transaction Date: DateTime\n",
    "\n",
    "# ?- Are there any obvious issues with data types or missing values?\n",
    "    # ^ There are missing values, values that have different ways of representing that they don't exist\n",
    "\n",
    "\n",
    "# TODO 1. Read the CSV file into a DataFrame.\n",
    "data = pd.read_csv('dirty_cafe_sales.csv')\n",
    "\n",
    "# TODO 2. Display the first 5 rows of the dataset.\n",
    "print(data.head(5))\n",
    "\n",
    "# TODO 3. Print the shape of the DataFrame.\n",
    "print(data.shape)\n",
    "\n",
    "# TODO 4. Use info() to inspect column data types and missing values.\n",
    "data.info()\n",
    "\n",
    "# TODO 5. Use describe() to view summary statistics for numerical columns.\n",
    "data.describe()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e916f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  3.,  1.,  5.,  4., nan])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "### ! Step 2 — Identify and Handle Missing Values\n",
    "\n",
    "# **Tasks:**\n",
    "# TODO 1. Identify how many missing values exist in each column.\n",
    "# TODO 2. Decide which numerical columns should be imputed using:\n",
    "#    - Mean, or\n",
    "#    - Median, or\n",
    "#    - Mode\n",
    "# TODO 3. Perform the imputation.\n",
    "# TODO 4. Verify that missing values have been handled correctly.\n",
    "\n",
    "# **Questions to answer:**\n",
    "# ?- Which columns contained missing values?\n",
    "# ^ all but the id column\n",
    "\n",
    "# ?- Why did you choose mean or median for each column?\n",
    "# ^ I chose the mean for all the numerical columns based on item because it will just give the correct value since it wouldn't change, or a good in approximation\n",
    "\n",
    "# ?- Were any columns dropped? If yes, explain why.\n",
    "# ^ I dropped the ID column, and I also dropped any values that were missing Payment or Location since you can't really impute those values and they are important for analysis\n",
    "\n",
    "# TODO 1. Identify how many missing values exist in each column.\n",
    "data.isna().sum()\n",
    "\n",
    "# TODO 2. Decide which numerical columns should be imputed using:\n",
    "# ^ Quantity: Numerical - mean by item\n",
    "# ^ Price Per Unit: Numerical - mean by item\n",
    "# ^ Total Spent: Numerical - quantity * price per unit\n",
    "\n",
    "# TODO 3. Perform the imputation.\n",
    "# ~ Quantity\n",
    "# data['Quantity'].unique()\n",
    "\n",
    "# errors = 'coerce' will convert non-numeric values to NaN, the line above is not really necessary but makes it cleaner\n",
    "data['Quantity'] = data['Quantity'].replace(['ERROR', 'UNKNOWN'], np.nan)\n",
    "data['Quantity'] = pd.to_numeric(data['Quantity'], errors='coerce')\n",
    "data['Quantity'] = data['Quantity'].fillna(data.groupby('Item')['Quantity'].transform('mean'))\n",
    "data['Quantity'] = data['Quantity'].round()\n",
    "\n",
    "# data['Quantity'].unique()\n",
    "\n",
    "# ~ Price Per Unit\n",
    "# data['Price Per Unit'].unique()\n",
    "\n",
    "data['Price Per Unit'] = data['Price Per Unit'].replace(['ERROR', 'UNKNOWN'], np.nan)\n",
    "data['Price Per Unit'] = pd.to_numeric(data['Price Per Unit'], errors='coerce')\n",
    "data['Price Per Unit'] = data['Price Per Unit'].fillna(data.groupby('Item')['Price Per Unit'].transform('mean'))\n",
    "data['Price Per Unit'] = data['Price Per Unit'].round()\n",
    "\n",
    "# data['Price Per Unit'].unique()\n",
    "# data[data['Price Per Unit'] < 1]\n",
    "# data[(data['Quantity' * data['Price Per Unit'] != data['Total Spent']]]\n",
    "\n",
    "# ~ Total Spent\n",
    "# Only update 'Total Spent' where it is null\n",
    "mask = data['Total Spent'].isna()\n",
    "data.loc[mask, 'Total Spent'] = data.loc[mask, 'Quantity'] * data.loc[mask, 'Price Per Unit']\n",
    "\n",
    "# ~ Remove rows with missing Payment Method or Location or Transaction Date and remove ID column, but I will keep an old version of the data for all the numerical values\n",
    "data[['Payment Method', 'Location', 'Transaction Date']] = data[['Payment Method', 'Location', 'Transaction Date']].replace(['ERROR', 'UNKNOWN'], np.nan)\n",
    "\n",
    "data_values = data.dropna(subset=['Quantity', 'Price Per Unit', 'Total Spent'])\n",
    "\n",
    "data_cleaned = data.dropna(subset=['Payment Method', 'Location', 'Transaction Date']).drop(columns=['Transaction ID'])\n",
    "\n",
    "# len(data_cleaned)\n",
    "\n",
    "# TODO 4. Verify that missing values have been handled correctly.\n",
    "data_cleaned.isna().sum()\n",
    "\n",
    "data['Quantity'].unique()\n",
    "data[data['Quantity'].isna()]\n",
    "\n",
    "data['Price Per Unit'].unique()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
